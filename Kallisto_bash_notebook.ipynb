{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA-Seq from scratch - Kallisto\n",
    "\n",
    "In this notebook we setup an [Atmosphere](https://atmo.cyverse.org/application) linux virtual machine so that we can analzye RNA-Seq data using [Kallisto](https://pachterlab.github.io/kallisto/). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software Installations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's install [miniconda](https://conda.io/miniconda.html). This is a software package that will help us easily install other software we might need. Although in this example we will be installing miniconda on a Linux machine, you can use the miniconda link above to download and install for your operating system (Windows, Mac, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Miniconda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let verify that we are in a directory that would be good for installing this software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are in our home directory, and for the purpose of this tutorial, this will be fine. Let's download the installation file using `wegt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh && ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the above cell we used `wget` to download `Miniconda3-latest-Linux-x86_64.sh` and also used the `ls` command to verify we downloaded the file. Now let's install it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bash Miniconda3-latest-Linux-x86_64.sh -b -p $HOME/miniconda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's tell the computer where miniconda is by exporting to path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export PATH=\"$HOME/miniconda/bin:$PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will configure conda so that it is aware of [bioconda](https://bioconda.github.io/index.html) packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conda config --add channels defaults\n",
    "conda config --add channels conda-forge\n",
    "conda config --add channels bioconda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Kallisto using Bioconda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can install Kallisto (one of [many packages](https://bioconda.github.io/recipes.html)) available on bioconda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we use the -y option so that we automatically accept all prompts\n",
    "conda install -y kallisto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's verify that kallisto is installed, and check the version by running the kallisto command with no arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kallisto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install SRA Tools and import data from SRA (optional)\n",
    "\n",
    "We need to obtain some test data to analyze. To do so, we will import some data from the [NCBI SRA](https://www.ncbi.nlm.nih.gov/sra). The data we are working with is and Arabidopsis dataset described [here](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA79729/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to get the list of accessings (sequencing runs) which is available for download here: https://www.ncbi.nlm.nih.gov/bioproject/PRJNA79729/. We are looking for the `SraRunTable.txtx` file. which can be downloaded here: https://www.ncbi.nlm.nih.gov/Traces/study/?acc=SRP003234. We have provided it on this instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head -n 4 $HOME/kallisto-rnaseq-jupyter/required_files/SraRunTable.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite hard to read, but we need the `Run` column to download read data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cut -f7 $HOME/kallisto-rnaseq-jupyter/required_files/SraRunTable.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do two things. We are going to use the [SRA Toolkit](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=toolkit_doc) to import the files we need from the SRA. Rather than do 19 downloads one-by-one, we can take this list of accessions and use a while loop to do the import. Also, for the purpose of this demo we won't download all 19 files but just take the first 1. Let's make a file that just has the first to entries from our `SraRunTable.txt`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cut -f7 $HOME/kallisto-rnaseq-jupyter/required_files/SraRunTable.txt |grep -v \"Run\"| head -n1 > sample_runs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the file we created. In the command above we just created a file that has a single SRA accession, but in principle you could do without the last pipe `| head -n1` and simply save all the accession IDs to `sample_runs.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat sample_runs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's use bioconda to install the Sra Toolkit and update our path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conda install -y sra-tools && export PATH=\"$HOME/miniconda/bin:$PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Optional - we have this data on the image so this can be skipped)** \n",
    "\n",
    "We will use a while loop to read the list of run names and import them from ncbi. There are some additional options we can use to import the data more quickly, but for now we will just use the simplest options. \n",
    "\n",
    "**(This takes about 5 minutes to import the data)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while read line; do prefetch $line; done<sample_runs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets move these files into a more convenient location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkdir $HOME/raw_data && mv $HOME/ncbi/public/sra/*.sra $HOME/raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two sra files in the `raw_data` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls $HOME/raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(OPTIONAL)** We now need to use another tool to convert these files into fastq format. We will covert them to a compressed (fastq.gz) format which can be directly used by Kallisto. This will take ~5 minutes per file (good thing we are only doing one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd $HOME/raw_data && for file in *.sra; do fastq-dump --gzip $file; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the data we need is on CyVerse, so we will use iCommands to import the rest of the dataset (much faster). While we haven't provided data on using iCommands and CyVerse Data Store, you can learn more about them at https://cyverse-data-store-guide.readthedocs-hosted.com/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rm $HOME/raw_data/*.sra # Get rid of the sra file we won't use \n",
    "mv $HOME/fastq_files $HOME/raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have our 19 fastq files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls $HOME/raw_data/fastq_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and run Kallisto\n",
    "\n",
    "Next we will get some reference transcriptome data and start the process of running Kallisto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import transcriptome data\n",
    "\n",
    "First, we will download the Arabdiopsis transcriptome data from [Ensemble](ftp://ftp.ensemblgenomes.org/pub/plants/release-39/fasta/arabidopsis_thaliana/cdna/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wget ftp://ftp.ensemblgenomes.org/pub/plants/release-39/fasta/arabidopsis_thaliana/cdna/Arabidopsis_thaliana.TAIR10.cdna.all.fa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the the checksum of the downloaded file with the [publushed sum](ftp://ftp.ensemblgenomes.org/pub/plants/release-39/fasta/arabidopsis_thaliana/cdna/CHECKSUMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum Arabidopsis_thaliana.TAIR10.cdna.all.fa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also organize our downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkdir transcriptome && mv Arabidopsis_thaliana.TAIR10.cdna.all.fa.gz transcriptome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index transcriptome\n",
    "\n",
    "We will now use Kallisto's indexing function to prepare the transcriptome for analysis. First let's organize our files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkdir $HOME/analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next run the indexing command. This prepares the transcriptome so that we can peudoalign reads to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kallisto index --index=\"athalianaTAIR10_index\" $HOME/raw_data/transcriptome/Arabidopsis_thaliana.TAIR10.cdna.all.fa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a transcriptome index which can now be used for pseudoalignment, we'll move it into the transcriptome folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mv athalianaTAIR10_index transcriptome/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify reads\n",
    "\n",
    "In this final step, we will run Kallisto on all of our files to quantify the reads. We will write a for loop to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwd\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All instructions for the commands we are using are in the Kallisto manual: https://pachterlab.github.io/kallisto/manual. *If needed, the results for this are located on the CyVerse Data commons at (/iplant/home/shared/cyverse_training/datasets/PRJNA79729/kallisto_quantified) and on the Amazon AMI in the dcuser home directory in the `.quantfied` folder.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd $HOME/raw_data/fastq_files\n",
    "for file in *.fastq.gz; do output=\"${file%.*.*}\"_quant; kallisto quant\\\n",
    " --single\\\n",
    " --index=$HOME/raw_data/transcriptome/athalianaTAIR10_index\\\n",
    " --single\\\n",
    " --bootstrap-samples=25\\\n",
    " --fragment-length=38\\\n",
    " --sd=1\\\n",
    " --output-dir=$output\\\n",
    " $file; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can move our results folders into our analysis folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mv $HOME/raw_data/fastq_files/*/ $HOME/analysis \n",
    "ls $HOME/analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
